{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import wfdb\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the record names in a list\n",
    "namelist = []\n",
    "namelist = namelist + list(range(100,125,1)) + list(range(200,235,1))\n",
    "for num in [110,120,204,206,211,216,218,224,225,226,227,229]:\n",
    "    namelist.remove(num)\n",
    "\n",
    "len(namelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window (signals, annotation, sec):\n",
    "    \"\"\"\n",
    "    this function gives a sec-seconds window (sec seconds before, sec seconds after the annotation mark)\n",
    "    of the ECG signals and assign value 1 if it's PVC beat and 0 otherwise.\n",
    "    parameter: signals: numpy array containing heart beat record values\n",
    "               annotation: wfdb.annotation object containing heart beat annotations\n",
    "               sec: positive integer number indicating the half-width of the window\n",
    "    return: two lists\n",
    "            siglist: a list of lists of length 360*2*sec \n",
    "            annlist: a list containing 1 if PVC beat, 0 otherwise\n",
    "    \"\"\"\n",
    "    siglist = []\n",
    "    annlist = []\n",
    "    \n",
    "    #loop through the annotation.symbol list\n",
    "    for i in range(len(annotation.symbol)):\n",
    "        timestamp = annotation.sample[i] #get the timestamp\n",
    "        \n",
    "        #test if that timestamp can have sec seconds before and after window\n",
    "        windowStart = timestamp - sec*annotation.fs\n",
    "        windowEnd = timestamp + sec*annotation.fs\n",
    "        if windowStart >= 0 & windowEnd <= len(signals):\n",
    "            if annotation.symbol[i] == 'V':\n",
    "                # check if the length of this strip is 360*2*sec\n",
    "                if len(signals[windowStart:windowEnd,].flatten().tolist()) == 2*sec*annotation.fs:\n",
    "                    siglist.append(signals[windowStart:windowEnd,].flatten().tolist())\n",
    "                    annlist.append(1)\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                # check if the length of this strip is 360*2*sec\n",
    "                if len(signals[windowStart:windowEnd,].flatten().tolist()) == 2*sec*annotation.fs:\n",
    "                    siglist.append(signals[windowStart:windowEnd,].flatten().tolist())\n",
    "                    annlist.append(0)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return siglist, annlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "record 100 is done.\n",
      "record 101 is done.\n",
      "record 102 is done.\n",
      "record 103 is done.\n",
      "record 104 is done.\n",
      "record 105 is done.\n",
      "record 106 is done.\n",
      "record 107 is done.\n",
      "record 108 is done.\n",
      "record 109 is done.\n",
      "record 111 is done.\n",
      "record 112 is done.\n",
      "record 113 is done.\n",
      "record 114 is done.\n",
      "record 115 is done.\n",
      "record 116 is done.\n",
      "record 117 is done.\n",
      "record 118 is done.\n",
      "record 119 is done.\n",
      "record 121 is done.\n",
      "record 122 is done.\n",
      "record 123 is done.\n",
      "record 124 is done.\n",
      "record 200 is done.\n",
      "record 201 is done.\n",
      "record 202 is done.\n",
      "record 203 is done.\n",
      "record 205 is done.\n",
      "record 207 is done.\n",
      "record 208 is done.\n",
      "record 209 is done.\n",
      "record 210 is done.\n",
      "record 212 is done.\n",
      "record 213 is done.\n",
      "record 214 is done.\n",
      "record 215 is done.\n",
      "record 217 is done.\n",
      "record 219 is done.\n",
      "record 220 is done.\n",
      "record 221 is done.\n",
      "record 222 is done.\n",
      "record 223 is done.\n",
      "record 228 is done.\n",
      "record 230 is done.\n",
      "record 231 is done.\n",
      "record 232 is done.\n",
      "record 233 is done.\n",
      "record 234 is done.\n"
     ]
    }
   ],
   "source": [
    "# loop through all record to get all the 10-seconds window signal list and annotation list\n",
    "# this could be the training dataset for the neural network model\n",
    "# this takes several minutes to run\n",
    "\n",
    "ECG_signals = []\n",
    "PVC_annotations = []\n",
    "\n",
    "for record in namelist:\n",
    "    signals, fields = wfdb.rdsamp(str(record), sampfrom=0, sampto='end', channels=[1], pb_dir='mitdb')\n",
    "    annotation = wfdb.rdann(str(record), 'atr', sampfrom=0, sampto=None, shift_samps=True, pb_dir='mitdb')\n",
    "    \n",
    "    signal_list, annotation_list = get_window(signals, annotation, 5)\n",
    "    \n",
    "    ECG_signals = ECG_signals + signal_list\n",
    "    PVC_annotations = PVC_annotations + annotation_list\n",
    "    \n",
    "    print('record', record, 'is done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111985"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ECG_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111985"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PVC_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 104886, 1: 7099})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are 7112 PVC 10-seconds window, 105186 non-PVC 10-seconds window\n",
    "Counter(PVC_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104886"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the index in PVC_annotations for normal beats\n",
    "\n",
    "normal_index = [i for i in range(len(PVC_annotations)) if PVC_annotations[i]==0]\n",
    "len(normal_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7099"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the index in PVC_annotations for PVC beats\n",
    "\n",
    "PVC_index = [i for i in range(len(PVC_annotations)) if PVC_annotations[i]==1]\n",
    "len(PVC_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly select 7099 normal beats\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(77)\n",
    "small_normal_index = random.sample(normal_index, 7099)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7099"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_normal_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[111839, 33939, 44009, 26542, 32244, 25993, 15648, 39353, 66405, 77501]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_normal_index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14198"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate 7099 normal beats index with 7099 PVC beats index\n",
    "# as small data index\n",
    "\n",
    "small_data_index = small_normal_index + PVC_index\n",
    "len(small_data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate samll dataset\n",
    "\n",
    "small_signals = []\n",
    "for i in small_data_index:\n",
    "    small_signals.append(ECG_signals[i])\n",
    "    \n",
    "small_annotations = []\n",
    "for i in small_data_index:\n",
    "    small_annotations.append(PVC_annotations[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14198"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14198"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write ECG signals data to csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('MIT-BIH-small.csv', 'w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerows(small_signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the PVC annotation data to csv file\n",
    "\n",
    "with open('MIT-BIH-Annotation-small.csv', 'w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(small_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform data into numpy array\n",
    "\n",
    "X = np.array(small_signals)\n",
    "y = np.array(small_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14198, 3600)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14198,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split train and test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9938, 3600)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9938,)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4260, 3600)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4260,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4983, 1: 4955})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the ratio of PVC beats in training set and test set\n",
    "\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2116, 1: 2144})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5032863849765258"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model accuracy\n",
    "\n",
    "2144/(2116+2144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take 2 minutes to run\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "y_train_pred = log_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4223,  760],\n",
       "       [ 885, 4070]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8344737371704568"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "(4223+4070)/(4223+760+885+4070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8213925327951564"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive Rate\n",
    "\n",
    "4070/(885+4070)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1525185631145896"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Positive Rate\n",
    "\n",
    "760/(4223+760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1619,  497],\n",
       "       [ 525, 1619]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing result\n",
    "\n",
    "y_test_pred = log_reg.predict(X_test)\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.760093896713615"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "(1619+1619)/(1619+497+525+1619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551305970149254"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive Rate\n",
    "\n",
    "1619/(525+1619)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23487712665406427"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Positive Rate\n",
    "\n",
    "497/(1619+497)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Dump the trained logistic regression model with Pickle\n",
    "LogReg_pkl_filename = 'LogRegSmall.pkl'\n",
    "\n",
    "# Open the file to save as pkl file\n",
    "LogReg_model_pkl = open(LogReg_pkl_filename, 'wb')\n",
    "pickle.dump(log_reg, LogReg_model_pkl)\n",
    "\n",
    "# Close the pickle instances\n",
    "LogReg_model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only takes 7 minutes to run\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4983,    0],\n",
       "       [1396, 3559]], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training set result\n",
    "\n",
    "y_train_pred = forest_reg.predict(X_train)\n",
    "y_train_pred = [int(x) for x in y_train_pred]\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8595290802978467"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "(4983+3559)/(4983+1396+3559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7182643794147326"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive Rate\n",
    "\n",
    "3559/(1396+3559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Positive Rate\n",
    "\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2106,   10],\n",
       "       [ 933, 1211]], dtype=int64)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing set result\n",
    "\n",
    "y_test_pred = forest_reg.predict(X_test)\n",
    "y_test_pred = [int(x) for x in y_test_pred]\n",
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7786384976525822"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "(2106+1211)/(2106+10+933+1211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5648320895522388"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive Rate\n",
    "\n",
    "1211/(933+1211)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004725897920604915"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Positive Rate\n",
    "\n",
    "10/(2106+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Dump the trained random forest classifier with Pickle\n",
    "RandomForest_pkl_filename = 'RandomForestSmall.pkl'\n",
    "\n",
    "# Open the file to save as pkl file\n",
    "RandomForest_model_pkl = open(RandomForest_pkl_filename, 'wb')\n",
    "pickle.dump(forest_reg, RandomForest_model_pkl)\n",
    "\n",
    "# Close the pickle instances\n",
    "RandomForest_model_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 3600\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 30\n",
    "n_outputs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "y = tf.placeholder(tf.int64, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# construct neural network\n",
    "\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, name='hidden1', activation=tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name='hidden2', activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name='outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define cost function\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define optimizer\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define evaluation\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create init and saver\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.86 Test accuracy: 0.797183\n",
      "1 Train accuracy: 0.88 Test accuracy: 0.834038\n",
      "2 Train accuracy: 0.88 Test accuracy: 0.854695\n",
      "3 Train accuracy: 0.92 Test accuracy: 0.870657\n",
      "4 Train accuracy: 0.94 Test accuracy: 0.878873\n",
      "5 Train accuracy: 0.96 Test accuracy: 0.881925\n",
      "6 Train accuracy: 0.98 Test accuracy: 0.884038\n",
      "7 Train accuracy: 0.98 Test accuracy: 0.888732\n",
      "8 Train accuracy: 0.94 Test accuracy: 0.892254\n",
      "9 Train accuracy: 1.0 Test accuracy: 0.89507\n",
      "10 Train accuracy: 0.96 Test accuracy: 0.89554\n",
      "11 Train accuracy: 0.94 Test accuracy: 0.901643\n",
      "12 Train accuracy: 0.94 Test accuracy: 0.902817\n",
      "13 Train accuracy: 1.0 Test accuracy: 0.902113\n",
      "14 Train accuracy: 1.0 Test accuracy: 0.902582\n",
      "15 Train accuracy: 0.98 Test accuracy: 0.906338\n",
      "16 Train accuracy: 0.98 Test accuracy: 0.909155\n",
      "17 Train accuracy: 0.96 Test accuracy: 0.908451\n",
      "18 Train accuracy: 0.98 Test accuracy: 0.91338\n",
      "19 Train accuracy: 0.98 Test accuracy: 0.912207\n",
      "20 Train accuracy: 0.98 Test accuracy: 0.917371\n",
      "21 Train accuracy: 1.0 Test accuracy: 0.916432\n",
      "22 Train accuracy: 1.0 Test accuracy: 0.919953\n",
      "23 Train accuracy: 1.0 Test accuracy: 0.91831\n",
      "24 Train accuracy: 1.0 Test accuracy: 0.91784\n",
      "25 Train accuracy: 1.0 Test accuracy: 0.919484\n",
      "26 Train accuracy: 1.0 Test accuracy: 0.920188\n",
      "27 Train accuracy: 1.0 Test accuracy: 0.921362\n",
      "28 Train accuracy: 1.0 Test accuracy: 0.920657\n",
      "29 Train accuracy: 1.0 Test accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "# execution\n",
    "\n",
    "n_epochs = 30\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(len(X_train)//batch_size):\n",
    "            batch_index = random.sample(range(len(X_train)), batch_size)\n",
    "            X_batch = X_train[batch_index]\n",
    "            y_batch = y_train[batch_index]\n",
    "            sess.run(training_op, feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_batch, y:y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "        print(epoch, 'Train accuracy:', acc_train, 'Test accuracy:', acc_test)\n",
    "        \n",
    "    save_path = saver.save(sess, './dnn_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./dnn_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, './dnn_model.ckpt')\n",
    "    Z = logits.eval(feed_dict={X:X_test})\n",
    "    y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1987,  129],\n",
       "       [ 202, 1942]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.922300469483568"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "(1987+1942)/(1987+129+202+1942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057835820895522"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# True Positive Rate\n",
    "\n",
    "1942/(202+1942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0609640831758034"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False Positive Rate\n",
    "\n",
    "129/(1987+129)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|model|accuracy|true positive rate|false positive rate|\n",
    "|-----|--------|------------------|-------------------|\n",
    "|baseline|0.5033|0.0|0.0|\n",
    "|Logistic Regression training|0.8345|0.8214|0.1525|\n",
    "|Logistic Regression testing|0.7601|0.7551|0.2349|\n",
    "|Random Forest training|0.8595|0.7183|0.0|\n",
    "|Random Forest testing|0.7786|0.5648|0.0047|\n",
    "|Neural Network training|1.0|||\n",
    "|Neural Network testing|0.9223|0.9056|0.0610|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
